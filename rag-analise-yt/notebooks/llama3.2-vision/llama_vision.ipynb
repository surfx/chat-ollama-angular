{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# llama3.2-vision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [llama3.2-vision](https://ollama.com/library/llama3.2-vision)\n",
    "- [OCR App with Ollama and Llama Vision - Install Locally](https://www.youtube.com/watch?v=x8J6rp7eZzA)\n",
    "- [git LLama3.2-OCR](https://github.com/patchy631/ai-engineering-hub/tree/main/llama-ocr)\n",
    "\n",
    "```bash\n",
    "ollama pull llama3.2-vision\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Depend√™ncias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd /tmp/uv_environments\n",
    "source my_env_3129/bin/activate\n",
    "uv pip install -U ipykernel streamlit ollama\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import streamlit as st\n",
    "import ollama\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "# Page configuration\n",
    "st.set_page_config(\n",
    "    page_title=\"Llama OCR\",\n",
    "    page_icon=\"ü¶ô\",\n",
    "    layout=\"wide\",\n",
    "    initial_sidebar_state=\"expanded\"\n",
    ")\n",
    "\n",
    "# Title and description in main area\n",
    "st.title(\"ü¶ô Llama OCR\")\n",
    "\n",
    "# Add clear button to top right\n",
    "col1, col2 = st.columns([6,1])\n",
    "with col2:\n",
    "    if st.button(\"Clear üóëÔ∏è\"):\n",
    "        if 'ocr_result' in st.session_state:\n",
    "            del st.session_state['ocr_result']\n",
    "        st.rerun()\n",
    "\n",
    "st.markdown('<p style=\"margin-top: -20px;\">Extract structured text from images using Llama 3.2 Vision!</p>', unsafe_allow_html=True)\n",
    "st.markdown(\"---\")\n",
    "\n",
    "# Move upload controls to sidebar\n",
    "with st.sidebar:\n",
    "    st.header(\"Upload Image\")\n",
    "    uploaded_file = st.file_uploader(\"Choose an image...\", type=['png', 'jpg', 'jpeg'])\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # Display the uploaded image\n",
    "        image = Image.open(uploaded_file)\n",
    "        st.image(image, caption=\"Uploaded Image\")\n",
    "        \n",
    "        if st.button(\"Extract Text üîç\", type=\"primary\"):\n",
    "            with st.spinner(\"Processing image...\"):\n",
    "                try:\n",
    "                    response = ollama.chat(\n",
    "                        model='llama3.2-vision',\n",
    "                        messages=[{\n",
    "                            'role': 'user',\n",
    "                            'content': \"\"\"Analyze the text in the provided image. Extract all readable content\n",
    "                                        and present it in a structured Markdown format that is clear, concise, \n",
    "                                        and well-organized. Ensure proper formatting (e.g., headings, lists, or\n",
    "                                        code blocks) as necessary to represent the content effectively.\"\"\",\n",
    "                            'images': [uploaded_file.getvalue()]\n",
    "                        }]\n",
    "                    )\n",
    "                    st.session_state['ocr_result'] = response.message.content\n",
    "                except Exception as e:\n",
    "                    st.error(f\"Error processing image: {str(e)}\")\n",
    "\n",
    "# Main content area for results\n",
    "if 'ocr_result' in st.session_state:\n",
    "    st.markdown(st.session_state['ocr_result'])\n",
    "else:\n",
    "    st.info(\"Upload an image and click 'Extract Text' to see the results here.\")\n",
    "\n",
    "# Footer\n",
    "st.markdown(\"---\")\n",
    "st.markdown(\"Made with ‚ù§Ô∏è using Llama Vision Model2 | [Report an Issue](https://github.com/patchy631/ai-engineering-hub/issues)\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env_3129",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
